{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos disponibles:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "WARNING:tensorflow:From C:\\Users\\migue\\AppData\\Local\\Temp\\ipykernel_18800\\328158102.py:9: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "\n",
      "✅ TensorFlow está usando la GPU.\n",
      "GPU en uso: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Ver dispositivos disponibles\n",
    "print(\"Dispositivos disponibles:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(device)\n",
    "\n",
    "# Ver si TensorFlow está usando GPU\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"\\n✅ TensorFlow está usando la GPU.\")\n",
    "    print(\"GPU en uso:\", tf.config.experimental.list_physical_devices('GPU'))\n",
    "else:\n",
    "    print(\"\\n❌ TensorFlow NO está usando la GPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, False)  # Usar toda la memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalAveragePooling2D, Activation, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functools\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREACION DE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              image_path      label\n",
      "86995  ../data/morton14k\\f_youtubeHTML5_1_9880.bin_mo...  streaming\n",
      "86996  ../data/morton14k\\f_youtubeHTML5_1_9888.bin_mo...  streaming\n",
      "86997  ../data/morton14k\\f_youtubeHTML5_1_990.bin_mor...  streaming\n",
      "86998  ../data/morton14k\\f_youtubeHTML5_1_9959.bin_mo...  streaming\n",
      "86999  ../data/morton14k\\f_youtubeHTML5_1_9987.bin_mo...  streaming\n",
      "       Cantidad  count\n",
      "0          chat  14500\n",
      "1         email  14500\n",
      "2         voice  14500\n",
      "3     streaming  14500\n",
      "4  filetransfer  14500\n",
      "5           p2p  14500\n"
     ]
    }
   ],
   "source": [
    "# Ruta al directorio donde están las imágenes\n",
    "data_dir = \"../data/morton14k\"\n",
    "\n",
    "# Definir reglas de clasificación\n",
    "CLASS_RULES = {\n",
    "    \"chat\": [\"chat\"],\n",
    "    \"email\": [\"email\"],\n",
    "    \"voice\": [\"audio\", \"voipbuster\"],\n",
    "    \"streaming\": [\"vimeo\", \"netflix\", \"spotify\", \"youtube\", \"video\"],\n",
    "    \"filetransfer\": [\"sftp\", \"ftps\", \"files\", \"file\"],\n",
    "    \"p2p\": [\"bittorrent\"]\n",
    "}\n",
    "\n",
    "# Función para asignar una etiqueta según el nombre del archivo\n",
    "def get_label(filename):\n",
    "    for category, keywords in CLASS_RULES.items():\n",
    "        if any(keyword in filename.lower() for keyword in keywords):\n",
    "            return category\n",
    "    return None  # Si no coincide con ninguna categoría\n",
    "\n",
    "# Recorrer la carpeta y subcarpetas para extraer información\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for root, _, files in os.walk(data_dir):  # Recorre todas las carpetas y archivos\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):  # Solo archivos PNG\n",
    "            label = get_label(file)\n",
    "            if label:  # Solo añadimos imágenes con una categoría válida\n",
    "                image_paths.append(os.path.join(root, file))  # Ruta completa\n",
    "                labels.append(label)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
    "\n",
    "# Mostrar las primeras filas para verificar\n",
    "print(df.tail())\n",
    "print(df[\"label\"].value_counts().to_frame().reset_index().rename(columns={\"index\": \"Etiqueta\", \"label\": \"Cantidad\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3) [1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario para convertir etiquetas en números\n",
    "label_map = {label: idx for idx, label in enumerate(df[\"label\"].unique())}\n",
    "df[\"label\"] = df[\"label\"].map(label_map)  # Convertimos a números\n",
    "\n",
    "# Función para cargar imágenes y etiquetas\n",
    "# Función para cargar imágenes y convertir etiquetas a one-hot encoding\n",
    "def load_image_label(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)  # Convertir PNG a tensor\n",
    "    img = tf.image.resize(img, (32, 32))  # Asegurar tamaño correcto\n",
    "    img = img / 255.0  # Normalización [0,1]\n",
    "\n",
    "    label = tf.one_hot(label, depth=6)  # Convertir etiqueta a one-hot\n",
    "    return img, label\n",
    "\n",
    "\n",
    "# Convertir el DataFrame en un Dataset de TensorFlow\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df[\"image_path\"].values, df[\"label\"].values))\n",
    "dataset = dataset.map(load_image_label)\n",
    "\n",
    "# Mostrar un ejemplo\n",
    "for img, label in dataset.take(1):  \n",
    "    print(img.shape, label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases en el dataset original:\n",
      "\n",
      "label\n",
      "0    14500\n",
      "1    14500\n",
      "2    14500\n",
      "3    14500\n",
      "4    14500\n",
      "5    14500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución de clases en el dataset de entrenamiento:\n",
      "label\n",
      "1    11600\n",
      "2    11600\n",
      "5    11600\n",
      "0    11600\n",
      "4    11600\n",
      "3    11600\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución de clases en el dataset de validación:\n",
      "label\n",
      "1    2900\n",
      "2    2900\n",
      "5    2900\n",
      "4    2900\n",
      "3    2900\n",
      "0    2900\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total imágenes en entrenamiento: 69600\n",
      "Total imágenes en validación: 17400\n"
     ]
    }
   ],
   "source": [
    "## SEPARACION DE TRAINING Y VALIDATION DATA\n",
    "\n",
    "# Ver distribución de clases antes de dividir\n",
    "print(\"Distribución de clases en el dataset original:\\n\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "# Dividir en entrenamiento y validación asegurando la estratificación\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "\n",
    "# Verificar distribución después de dividir\n",
    "print(\"\\nDistribución de clases en el dataset de entrenamiento:\")\n",
    "print(train_df[\"label\"].value_counts())\n",
    "\n",
    "print(\"\\nDistribución de clases en el dataset de validación:\")\n",
    "print(val_df[\"label\"].value_counts())\n",
    "\n",
    "# Crear datasets de TensorFlow\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_df[\"image_path\"].values, train_df[\"label\"].values))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_df[\"image_path\"].values, val_df[\"label\"].values))\n",
    "\n",
    "# Aplicar la función de carga de imágenes\n",
    "train_dataset = train_dataset.map(load_image_label)\n",
    "val_dataset = val_dataset.map(load_image_label)\n",
    "\n",
    "# Contar elementos en los datasets de TensorFlow\n",
    "train_count = sum(1 for _ in train_dataset)\n",
    "val_count = sum(1 for _ in val_dataset)\n",
    "\n",
    "print(f\"\\nTotal imágenes en entrenamiento: {train_count}\")\n",
    "print(f\"Total imágenes en validación: {val_count}\")\n",
    "\n",
    "# Mezclar, agrupar en batches y optimizar\n",
    "batch_size = 64\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.shuffle(1000).batch(batch_size).prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTUAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m      4\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      6\u001b[0m label_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memail\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;241m5\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2p\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m data_augmentation \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     16\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomFlip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal_and_vertical\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     17\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomRotation(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     18\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomZoom(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     19\u001b[0m ])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# MODELO\u001b[39;00m\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     24\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m),\n\u001b[0;32m     25\u001b[0m     \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;28mlen\u001b[39m(label_map), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Usar len(label_map) para las 6 clases\u001b[39;00m\n\u001b[0;32m     46\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "IMG_SIZE = (32, 32)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "\n",
    "label_map = {\n",
    "    0: 'chat',\n",
    "    1: 'email',\n",
    "    2: 'voice',\n",
    "    3: 'streaming',\n",
    "    4: 'filetransfer',\n",
    "    5: 'p2p'\n",
    "}\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# MODELO\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # No usamos data aug porque no funciona bien\n",
    "    layers.Rescaling(1./255),\n",
    "    \n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(32, 32, 1)),  # Cambiar 1 a 3 para 3 canales\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(label_map), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
    "\n",
    "# Evaluación del modelo en el conjunto de validación\n",
    "val_labels = np.array(val_df[\"label\"])  # Etiquetas reales\n",
    "predictions = model.predict(val_dataset)\n",
    "pred_labels = np.argmax(predictions, axis=1)  # Etiquetas predichas\n",
    "\n",
    "# Matriz de Confusión\n",
    "conf_matrix = confusion_matrix(val_labels, pred_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\n📊 Classification Report:\\n\")\n",
    "print(classification_report(val_labels, pred_labels, target_names=label_map.keys()))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pito",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
